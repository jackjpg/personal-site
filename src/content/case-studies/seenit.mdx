---
title: "Screenshots as a new social primitive"
subtitle: "Turning Gen Z's most honest digital behavior into a new form of self-expression"
introduction: |
  Gen Z takes 20–25 screenshots a day. From wanted clothes to breakup memes, it's their most honest digital behaviour, and they just sit hidden in camera albums.

  Could LLMs make sense of screenshots and turn them into a new form of self-expression? As founding designer at Seenit, this is what I set out to answer. I defined screenshots as a new social primitive and built the first interface to prove it.

  In six weeks, I partnered with an engineer to ship an MVP that turned private screenshots into weekly visible summaries. What I learned shaped the next iteration: a working Swift prototype which moved from performance to friendship.

  Impact: Launched TestFlight with 20-30% share rate
date: "2024"
role: "Founding Product Designer"
client: "Seenit"
---

<CSImage 
  src="/Project_seenit/Seenitprototype.mov" 
  alt="Seenit app overview"
  aspectRatio="none"
/>

<Section title="Defining the bet: Can screenshots power response-driven sharing?">

To move from idea to product, I broke the problem into three behavioural pillars, signals that would tell us if screenshot-as-status could sustain a real loop:

1. Expression: can AI turn mundane screenshots into something share-worthy?
2. Reaction: do they spark replies or stories in existing channels?
3. Usage: can it become a sustained behaviour, not just novel?

</Section>

<Section title="First bet: Weekly summaries">

<CSYouTube 
  url="https://youtube.com/shorts/2FJmm4j1k6I"
  title="Weekly summaries experiment"
/>

I partnered with an engineer to ship the first experiment: a weekly Sunday card that told the story of your week. In six weeks we went from a hypothesis to a live Testflight build.

- Tone testing gave us intuition: Each week we shifted the LLM's output (dry, playful, reflective) and gave users three cards to flick between. Meme-like captions consistently got the strongest response.
- Behaviour revealed the limits of summaries: The format hit a 20–30% share rate and saw organic adoption between friends, but re-engagement came from comparison, not reflection. Shares didn't go to IG; they moved into whatsapp and group chats.
- Summaries closed loops; they didn't create them. The best cards captured the the small, throwaway moments, the things people wouldn't usually share, but felt human and created reactions

</Section>

<Section title="Pivot: Presence over summaries">

After 3 weeks, we saw our usage numbers drop. Users didn't want a scrapbook, they wanted a sticker.

In response to feedback and analysis, I designed the core mechanic over a weekend. The goal was to lean into what we had learned through the first experiment: presence between friends, comparison, and throwaway moments. The output became shorter, punchier, funnier. In addition to the core mechanic, it became a friendship app, allowing a group of 6 people. In the video above you can see the feed, with the POV's generated from just a few screenshots and an LLM pipeline.

</Section>

<Section title="Adding a status">

Adding a status happens without opening the app. When users get a push reminder, either because they haven't shared in a while, or a friend has, a back tap triggers a lightweight status, AI-generated from 1–2 screenshots and shared to their squad. There's no post to craft, no caption to write, no feed to perform into. It's an interface that's passive in input, invisible in action, intelligent in output.

Push → Screenshots → llm interprets behaviour → generates status + POV + reactions → shares to friends

Unlike other social apps that rely on active input, Seenit is built from what people already do but never show.

</Section>

<Section title="Extending presence through avatars">

To extend presence beyond drops, I prototyped an invisible avatar system that used a diffusion model to turn an IG display photo into a recognisable, playful, personality-driven characters. Each avatar was carried across profiles, widgets, invites, and feed — forming an ambient identity layer that matched the product's tone.

</Section>

